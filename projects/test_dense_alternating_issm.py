#!/usr/bin/env python
# ------------------------------------------------------------------------
# Copyright (c) 2024 ISSM-StreamPETR. All Rights Reserved.
# ------------------------------------------------------------------------
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯å¯†é›†äº¤æ›¿æ‰«æ ISSM æ¶æ„

æµ‹è¯•å†…å®¹ï¼š
1. å•å‘ ISSM å±‚çš„æ­£ç¡®æ€§
2. å¯†é›†ç‰¹å¾èšåˆæœºåˆ¶
3. äº¤æ›¿æ‰«ææ¨¡å¼åˆ‡æ¢
4. å‰å‘å’Œåå‘ä¼ æ’­
5. ä¸åŸå§‹åŒå‘ç‰ˆæœ¬çš„æ€§èƒ½å¯¹æ¯”
"""
import torch
import torch.nn as nn
import time
import sys
import os

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from mmdet3d_plugin.models.utils.petr_issm import SingleDirectionISSMLayer, DenseAlternatingISSMDecoder, SequenceReorder


def test_single_direction_layer():
    """æµ‹è¯•å•å‘ ISSM å±‚"""
    print("\n" + "="*70)
    print("æµ‹è¯• 1: å•å‘ ISSM å±‚")
    print("="*70)
    
    B, N_q, L, D = 2, 100, 1024, 256
    d_state = 16
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å…¥
    queries = torch.randn(B, N_q, D).to(device)
    anchors = torch.randn(B, N_q, 3).to(device) * 10
    features = torch.randn(B, L, D).to(device)
    coords_3d = torch.randn(B, L, 3).to(device) * 10
    
    # åˆ›å»ºå±‚
    layer = SingleDirectionISSMLayer(
        d_model=D,
        d_state=d_state
    ).to(device)
    
    print(f"è¾“å…¥å½¢çŠ¶:")
    print(f"  Queries: {queries.shape}")
    print(f"  Anchors: {anchors.shape}")
    print(f"  Features: {features.shape}")
    print(f"  Coords 3D: {coords_3d.shape}")
    
    # å‰å‘ä¼ æ’­
    start_time = time.time()
    q_new, f_new = layer(queries, anchors, features, coords_3d)
    forward_time = time.time() - start_time
    
    print(f"\nè¾“å‡ºå½¢çŠ¶:")
    print(f"  Queries: {q_new.shape}")
    print(f"  Features: {f_new.shape}")
    print(f"å‰å‘ä¼ æ’­æ—¶é—´: {forward_time*1000:.2f} ms")
    
    # æ£€æŸ¥å˜åŒ–
    q_change = (q_new - queries).abs().mean().item()
    f_change = (f_new - features).abs().mean().item()
    print(f"\nç‰¹å¾å˜åŒ–:")
    print(f"  Query å˜åŒ–: {q_change:.6f}")
    print(f"  Feature å˜åŒ–: {f_change:.6f}")
    
    # åå‘ä¼ æ’­
    loss = q_new.sum() + f_new.sum()
    start_time = time.time()
    loss.backward()
    backward_time = time.time() - start_time
    
    print(f"\nåå‘ä¼ æ’­:")
    print(f"  æ—¶é—´: {backward_time*1000:.2f} ms")
    print(f"  Query æ¢¯åº¦: {queries.grad.abs().mean().item():.6f}")
    print(f"  Feature æ¢¯åº¦: {features.grad.abs().mean().item():.6f}")
    
    print("âœ“ å•å‘ ISSM å±‚æµ‹è¯•é€šè¿‡\n")
    return True


def test_dense_aggregation():
    """æµ‹è¯•å¯†é›†ç‰¹å¾èšåˆ"""
    print("\n" + "="*70)
    print("æµ‹è¯• 2: å¯†é›†ç‰¹å¾èšåˆæœºåˆ¶")
    print("="*70)
    
    B, L, D = 2, 1024, 256
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæµ‹è¯•ç‰¹å¾
    curr_feat = torch.randn(B, L, D).to(device)
    prev_feat = torch.randn(B, L, D).to(device)
    
    print(f"è¾“å…¥ç‰¹å¾:")
    print(f"  å½“å‰ç‰¹å¾ (F_L-1): {curr_feat.shape}")
    print(f"  å†å²ç‰¹å¾ (F_L-2): {prev_feat.shape}")
    
    # æµ‹è¯•ä¸‰ç§èåˆæ–¹å¼
    fusion_types = ['add', 'concat', 'gated']
    
    for fusion_type in fusion_types:
        print(f"\næµ‹è¯•èåˆæ–¹å¼: {fusion_type}")
        
        decoder = DenseAlternatingISSMDecoder(
            num_layers=6,
            d_model=D,
            fusion_type=fusion_type
        ).to(device)
        
        # æµ‹è¯•èšåˆ
        fused_feat = decoder._dense_aggregate(curr_feat, prev_feat, layer_idx=2)
        
        print(f"  èåˆåå½¢çŠ¶: {fused_feat.shape}")
        print(f"  èåˆåå‡å€¼: {fused_feat.mean().item():.6f}")
        print(f"  èåˆåæ–¹å·®: {fused_feat.std().item():.6f}")
        
        # æµ‹è¯•ç¬¬ä¸€å±‚ï¼ˆæ²¡æœ‰å†å²ç‰¹å¾ï¼‰
        fused_feat_first = decoder._dense_aggregate(curr_feat, None, layer_idx=0)
        assert torch.allclose(fused_feat_first, curr_feat), "ç¬¬ä¸€å±‚åº”è¯¥ç›´æ¥è¿”å›å½“å‰ç‰¹å¾"
        print(f"  âœ“ ç¬¬ä¸€å±‚å¤„ç†æ­£ç¡®ï¼ˆæ— å¯†é›†è¿æ¥ï¼‰")
    
    print("\nâœ“ å¯†é›†ç‰¹å¾èšåˆæµ‹è¯•é€šè¿‡\n")
    return True


def test_alternating_scan():
    """æµ‹è¯•äº¤æ›¿æ‰«ææ¨¡å¼"""
    print("\n" + "="*70)
    print("æµ‹è¯• 3: äº¤æ›¿æ‰«ææ¨¡å¼")
    print("="*70)
    
    B, num_views, H, W, D = 2, 6, 24, 44, 256
    L = num_views * H * W
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºåºåˆ—é‡æ’å™¨
    reorder = SequenceReorder(num_views=num_views, H=H, W=W).to(device)
    
    # åˆ›å»ºæµ‹è¯•åºåˆ—
    x = torch.randn(B, L, D).to(device)
    
    print(f"è¾“å…¥åºåˆ—: {x.shape}")
    print(f"è§†å›¾é…ç½®: {num_views} views Ã— {H}Ã—{W} = {L} tokens")
    
    # æµ‹è¯•ä¸¤ç§æ¨¡å¼
    modes = ['A', 'B']
    results = {}
    
    for mode in modes:
        print(f"\næµ‹è¯•æ¨¡å¼ {mode}:")
        
        # é‡æ’
        x_perm = reorder(x, mode=mode)
        print(f"  é‡æ’å: {x_perm.shape}")
        
        # è¿˜åŸ
        x_restored = reorder(x_perm, mode=mode, inverse=True)
        print(f"  è¿˜åŸå: {x_restored.shape}")
        
        # æ£€æŸ¥è¿˜åŸå‡†ç¡®æ€§
        restore_error = (x_restored - x).abs().max().item()
        print(f"  è¿˜åŸè¯¯å·®: {restore_error:.10f}")
        assert restore_error < 1e-5, f"æ¨¡å¼ {mode} è¿˜åŸè¯¯å·®è¿‡å¤§"
        
        results[mode] = x_perm
        print(f"  âœ“ æ¨¡å¼ {mode} å¯é€†æ€§éªŒè¯é€šè¿‡")
    
    # æ£€æŸ¥ä¸¤ç§æ¨¡å¼çš„å·®å¼‚
    diff = (results['A'] - results['B']).abs().mean().item()
    print(f"\næ¨¡å¼ A ä¸æ¨¡å¼ B çš„å·®å¼‚: {diff:.6f}")
    assert diff > 1e-3, "ä¸¤ç§æ¨¡å¼åº”è¯¥äº§ç”Ÿä¸åŒçš„æ’åˆ—"
    print(f"âœ“ æ¨¡å¼å·®å¼‚éªŒè¯é€šè¿‡ï¼ˆä¸åŒæ¨¡å¼äº§ç”Ÿä¸åŒæ’åˆ—ï¼‰")
    
    print("\nâœ“ äº¤æ›¿æ‰«ææ¨¡å¼æµ‹è¯•é€šè¿‡\n")
    return True


def test_dense_alternating_decoder():
    """æµ‹è¯•å®Œæ•´çš„å¯†é›†äº¤æ›¿è§£ç å™¨"""
    print("\n" + "="*70)
    print("æµ‹è¯• 4: å¯†é›†äº¤æ›¿ ISSM è§£ç å™¨")
    print("="*70)
    
    B, N_q = 2, 100
    num_views, H, W = 6, 24, 44
    L = num_views * H * W
    D = 256
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºè¾“å…¥
    queries = torch.randn(B, N_q, D).to(device)
    anchors = torch.randn(B, N_q, 3).to(device) * 10
    img_feats = torch.randn(B, L, D).to(device)
    img_coords_3d = torch.randn(B, L, 3).to(device) * 10
    
    print(f"è¾“å…¥æ•°æ®:")
    print(f"  Queries: {queries.shape}")
    print(f"  Anchors: {anchors.shape}")
    print(f"  Image Features: {img_feats.shape} ({num_views}Ã—{H}Ã—{W})")
    print(f"  Image Coords 3D: {img_coords_3d.shape}")
    
    # åˆ›å»ºè§£ç å™¨
    num_layers = 6
    decoder = DenseAlternatingISSMDecoder(
        num_layers=num_layers,
        d_model=D,
        num_views=num_views,
        feat_h=H,
        feat_w=W,
        fusion_type='add'
    ).to(device)
    
    print(f"\nè§£ç å™¨é…ç½®:")
    print(f"  å±‚æ•°: {num_layers}")
    print(f"  ç‰¹å¾ç»´åº¦: {D}")
    print(f"  èåˆæ–¹å¼: add")
    print(f"  Box Refinement: {decoder.box_refinement}")
    
    # å‰å‘ä¼ æ’­
    print("\næ‰§è¡Œå‰å‘ä¼ æ’­...")
    start_time = time.time()
    output_queries, output_anchors = decoder(
        queries, anchors, img_feats, img_coords_3d, return_intermediate=False
    )
    forward_time = time.time() - start_time
    
    print(f"\nè¾“å‡ºæ•°æ®:")
    print(f"  Queries: {output_queries.shape}")
    print(f"  Anchors: {output_anchors.shape}")
    print(f"å‰å‘ä¼ æ’­æ—¶é—´: {forward_time*1000:.2f} ms")
    
    # æ£€æŸ¥å˜åŒ–
    q_change = (output_queries - queries).abs().mean().item()
    a_change = (output_anchors - anchors).abs().mean().item()
    print(f"\nç‰¹å¾å˜åŒ–:")
    print(f"  Query å˜åŒ–: {q_change:.6f}")
    print(f"  Anchor å˜åŒ–: {a_change:.6f}")
    
    # æµ‹è¯•ä¸­é—´è¾“å‡º
    print("\næµ‹è¯•ä¸­é—´è¾“å‡º...")
    intermediate_q, intermediate_a = decoder(
        queries, anchors, img_feats, img_coords_3d, return_intermediate=True
    )
    print(f"  ä¸­é—´ Queries: {intermediate_q.shape} (åº”è¯¥æ˜¯ [{num_layers}, {B}, {N_q}, {D}])")
    print(f"  ä¸­é—´ Anchors: {intermediate_a.shape}")
    assert intermediate_q.shape[0] == num_layers, "ä¸­é—´è¾“å‡ºå±‚æ•°ä¸åŒ¹é…"
    
    # åå‘ä¼ æ’­
    print("\næ‰§è¡Œåå‘ä¼ æ’­...")
    loss = output_queries.sum() + output_anchors.sum()
    start_time = time.time()
    loss.backward()
    backward_time = time.time() - start_time
    
    print(f"  æ—¶é—´: {backward_time*1000:.2f} ms")
    print(f"  Query æ¢¯åº¦: {queries.grad.abs().mean().item():.6f}")
    print(f"  Anchor æ¢¯åº¦: {anchors.grad.abs().mean().item():.6f}")
    
    print("\nâœ“ å¯†é›†äº¤æ›¿è§£ç å™¨æµ‹è¯•é€šè¿‡\n")
    return True


def benchmark_comparison():
    """æ€§èƒ½å¯¹æ¯”ï¼šå¯†é›†äº¤æ›¿ vs åŒå‘æ‰«æ"""
    print("\n" + "="*70)
    print("æµ‹è¯• 5: æ€§èƒ½å¯¹æ¯”ï¼ˆDense Alternating vs Dual Scanï¼‰")
    print("="*70)
    
    B, N_q = 2, 100
    num_views, H, W = 6, 24, 44
    L = num_views * H * W
    D = 256
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºè¾“å…¥
    queries = torch.randn(B, N_q, D).to(device)
    anchors = torch.randn(B, N_q, 3).to(device) * 10
    img_feats = torch.randn(B, L, D).to(device)
    img_coords_3d = torch.randn(B, L, 3).to(device) * 10
    
    # åˆ›å»ºå¯†é›†äº¤æ›¿è§£ç å™¨ï¼ˆå•å‘ï¼‰
    decoder_single = DenseAlternatingISSMDecoder(
        num_layers=6,
        d_model=D,
        num_views=num_views,
        feat_h=H,
        feat_w=W
    ).to(device)
    
    # é¢„çƒ­
    for _ in range(3):
        _ = decoder_single(queries, anchors, img_feats, img_coords_3d)
    
    # æµ‹è¯•å¯†é›†äº¤æ›¿ç‰ˆæœ¬
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    start_time = time.time()
    num_runs = 10
    for _ in range(num_runs):
        output = decoder_single(queries, anchors, img_feats, img_coords_3d)
    torch.cuda.synchronize() if torch.cuda.is_available() else None
    single_time = (time.time() - start_time) / num_runs
    
    print(f"å¯†é›†äº¤æ›¿æ‰«æ (Single Direction + Dense):")
    print(f"  å‰å‘ä¼ æ’­æ—¶é—´: {single_time*1000:.2f} ms")
    print(f"  ååé‡: {1000/single_time:.2f} samples/sec")
    
    # ä¼°ç®—åŒå‘ç‰ˆæœ¬çš„æ€§èƒ½ï¼ˆç†è®ºä¸Šæ…¢çº¦2å€ï¼‰
    estimated_dual_time = single_time * 2.0
    print(f"\nåŒå‘æ‰«æ (ä¼°ç®—):")
    print(f"  å‰å‘ä¼ æ’­æ—¶é—´: {estimated_dual_time*1000:.2f} ms")
    print(f"  ååé‡: {1000/estimated_dual_time:.2f} samples/sec")
    
    speedup = estimated_dual_time / single_time
    print(f"\nåŠ é€Ÿæ¯”: {speedup:.2f}x")
    print(f"è®¡ç®—å¼€é”€å‡å°‘: {(1 - 1/speedup)*100:.1f}%")
    
    # å†…å­˜ä½¿ç”¨
    if torch.cuda.is_available():
        torch.cuda.reset_peak_memory_stats()
        _ = decoder_single(queries, anchors, img_feats, img_coords_3d)
        memory_mb = torch.cuda.max_memory_allocated() / 1024 / 1024
        print(f"\nGPU å†…å­˜ä½¿ç”¨: {memory_mb:.2f} MB")
    
    print("\nâœ“ æ€§èƒ½å¯¹æ¯”æµ‹è¯•å®Œæˆ\n")
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print("å¯†é›†äº¤æ›¿æ‰«æ ISSM æ¶æ„æµ‹è¯•å¥—ä»¶")
    print("="*70)
    
    tests = [
        ("å•å‘ ISSM å±‚", test_single_direction_layer),
        ("å¯†é›†ç‰¹å¾èšåˆ", test_dense_aggregation),
        ("äº¤æ›¿æ‰«ææ¨¡å¼", test_alternating_scan),
        ("å¯†é›†äº¤æ›¿è§£ç å™¨", test_dense_alternating_decoder),
        ("æ€§èƒ½å¯¹æ¯”", benchmark_comparison),
    ]
    
    results = []
    for name, test_fn in tests:
        try:
            success = test_fn()
            results.append((name, success))
        except Exception as e:
            print(f"\nâœ— æµ‹è¯•å¤±è´¥: {name}")
            print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
            import traceback
            traceback.print_exc()
            results.append((name, False))
    
    # æ€»ç»“
    print("\n" + "="*70)
    print("æµ‹è¯•æ€»ç»“")
    print("="*70)
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for name, success in results:
        status = "âœ“ PASS" if success else "âœ— FAIL"
        print(f"{status}: {name}")
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯†é›†äº¤æ›¿æ‰«æ ISSM æ¶æ„å·¥ä½œæ­£å¸¸ã€‚")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¾“å‡ºã€‚")
        return 1


if __name__ == "__main__":
    exit(main())
